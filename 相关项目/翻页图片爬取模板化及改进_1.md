制作翻页图片爬取模板，尽可能通用于图片素材网站的资源获取  
根据需求逐步更新，完善功能   
此处使用某图片写真网站做测试

**以下是代码:**
> 运行版本为python 3.7

> 功能简介：  
> * 菜单式选项，翻页类型，能翻页选取完整内容
> * 使用urllib+lxml解析网页
> * 能一次选择多个项目，多进程并行下载


***
```

import os
import urllib.request
from lxml import etree
from multiprocessing import Process


#定义主地址和字典
url = 'http://www.m8jpg.com'
headers={"user-agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36"}
menulist = {1: "xinggang", 2: "meixiong", 3: "meitun", 4: "meitui"}
menuurl = {1: "/xinggan/", 2: "/meixiong/", 3: "/meitun/", 4: "/meitui/"}


def get_html(url):
    """
    网页解析
    """
    request = urllib.request.Request(url, headers=headers)
    html = urllib.request.urlopen(request).read()
    return html


def menu():
    """
    菜单式选项
    """
    for i in range(1,5):
        print (i, menulist[i])
    menunum = []
    num = 0
    while True:
        num = int(input('请输入所选栏目对应数字：(输入0确认结束)\n'))
        if num == 0:
            break
        menunum.append(num)
    page=int(input('请输入想要下载的页数:\n'))
    page_list=range(1,page+1)
    #分项，分页下载
    for inum in menunum:
        for ipage in page_list:
            p = Process(target=process, args=(inum,ipage))
            p.start()


def process(num,page):
    """
    载入进程
    """
    print ('正在进入...')
    print (num,menulist[num],'第%d页'%(page))
    #首页地址差异
    if page!=1:
        firurl='%s%sindex_%d.html'%(url,menuurl[num],page)
    else:
        firurl='%s%sindex.html'%(url,menuurl[num])
    print (firurl)
    #一级地址载入
    html = get_html(firurl)
    content = etree.HTML(html)
    #取得一级地址中的文件名称和二级地址
    namelist = content.xpath('//li[@class="i_list list_n2"]/a/@title')
    urllist = content.xpath('//li[@class="i_list list_n2"]/a/@href')
    imgnamelist = []
    securllist = []
    #xpath方法得到的是列表，遍历读出
    for iname in namelist:
        imgnamelist.append(iname)
    for iurl in urllist:
        securl = url + iurl
        securllist.append(securl)
    #先创建文件夹，再载入内容
    mkfolder(num,imgnamelist)
    loadpage(num,securllist,imgnamelist)


def mkfolder(num,imgnamelist):
    """
    创建文件夹
    """
    path = 'F:/BeautyPic/%s'%(menulist[num])
    for imgname in imgnamelist:
        ipath='%s/%s'%(path,imgname)
        os.makedirs(ipath)
        
        
def loadpage(num,securllist,imgnamelist):
    """
    载入页面
    """
    
    i = 0
    #二级地址载入，注意此处img/sec两个列表元素一一对应，i从0计数
    for securl in securllist:
        html = get_html(securl)
        content = etree.HTML(html)
        #取得每个文件名称对应的页数
        pagenum = content.xpath('//div[@class="nav-links page_imges"]/a/b/text()')
        page_range=range(1,int(pagenum[1])+1)
        #此处用num_ex防止num参数传递报错
        for num_ex in page_range:
            thiurl=securl
            if num_ex!=1:
                thiurl='%s_%d.html'%(thiurl[:-5],num_ex)
            html=get_html(thiurl)
            content=etree.HTML(html)
            #二级地址取得的src标签中仍是短地址，加工成三级地址
            thiurl = content.xpath('//div[@class="image_div"]/img/@src')
            imgurl=url+thiurl[0]        
            writepage(num, imgurl, imgnamelist[i])
        i+=1
    print ('全部下载已完成...')


def writepage( num, imgurl, imgname):
    """
    下载数据
    """
    path = 'F:/BeautyPic/%s/%s/%s'%(menulist[num],imgname,imgurl[-10:])
    #三级地址，即图片地址载入
    image = get_html(imgurl)
    print('正在下载...')
    print(path)
    with open(path,'wb') as f: 
        f.write(image)
    print('当前项下载已完成...')
        
        
if __name__ == '__main__':
    menu()
```
***

### to be continued...

