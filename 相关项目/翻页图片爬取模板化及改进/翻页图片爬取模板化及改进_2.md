
> 更新功能：  
> 加入页数选择，可选取指定的页数区间  
> 将解析方式换为requests+BeautifulSoup

***
```
import os
import requests
from bs4 import BeautifulSoup
from multiprocessing import Process


#定义主地址和字典
url = 'http://www.m8jpg.com'
headers={"user-agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36"}
menulist = {1: "xinggang", 2: "meixiong", 3: "meitun", 4: "meitui"}
menuurl = {1: "/xinggan/", 2: "/meixiong/", 3: "/meitun/", 4: "/meitui/"}


def get_html(url):
    """
    网页解析
    """
    res = requests.get(url, headers=headers)
    #根据网页编码解码
    res.encoding='utf8' 
    html=res.text
    return html


def menu():
    """
    菜单式选项
    """
    for i in range(1,5):
        print (i, menulist[i])
        
    input('请按提示依次输入所选栏目数字以及页数范围(按任意键继续):\n')
    menusel=[]
    while True:
        num=int(input('请输入所选栏目数字:\n'))
        page1=int(input('请输入需要下载的起始页数:\n'))
        page2=int(input('请输入需要下载的终止页数:\n'))
        jud=input('请输入"end"结束输入或输入其他键继续选择栏目:\n')
        menusel.append((num,page1,page2+1))
        if jud=='end':
            break
    #用元组列表存储输入值，分项，分页数区间       
    for imenu in menusel:
        num=imenu[0]
        pagelist=range(imenu[1],imenu[2])
        for page in pagelist:
            p=Process(target=process,args=(num,page))
            p.start()


def process(num,page):
    """
    载入进程
    """
    print ('正在进入...')
    print (num,menulist[num],'第%d页'%(page))
    #首页地址差异
    if page!=1:
        firurl='%s%sindex_%d.html'%(url,menuurl[num],page)
    else:
        firurl='%s%sindex.html'%(url,menuurl[num])
    print (firurl)
    #一级地址载入
    html = get_html(firurl)

    #用find方法取标签
    soup=BeautifulSoup(html,'lxml')
    soup=soup.find_all('li',class_="i_list list_n2")
    imgnamelist=[]
    securllist=[]
    #取得一级地址中的文件名称和二级地址
    for isoup in soup:
        securl=url+isoup.find('a').get('href')
        securllist.append(securl)
        imgnamelist.append((isoup.find('a').get('title')))

    #先创建文件夹，再载入内容
    mkfolder(num,imgnamelist)
    loadpage(num,securllist,imgnamelist)


def mkfolder(num,imgnamelist):
    """
    创建文件夹
    """
    path = 'F:/BeautyPic/%s'%(menulist[num])
    for imgname in imgnamelist:
        ipath='%s/%s'%(path,imgname)
        os.makedirs(ipath)
        
        
def loadpage(num,securllist,imgnamelist):
    """
    载入页面
    """
    
    i = 0
    #二级地址载入，注意此处img/sec两个列表元素一一对应，i从0计数
    for securl in securllist:
        html = get_html(securl)
        soup=BeautifulSoup(html,'lxml')
        #取得每个文件名称对应的页数
        pagenum = soup.find('div',class_="nav-links page_imges").find('a').find_all('b')[-1].get_text()
        page_range=range(1,int(pagenum)+1)
        #此处用num_ex防止num参数传递报错
        for num_ex in page_range:
            thiurl=securl
            if num_ex!=1:
                thiurl='%s_%d.html'%(thiurl[:-5],num_ex)
            html=get_html(thiurl)
            soup=BeautifulSoup(html,'lxml')
            #二级地址取得的src标签中仍是短地址，加工成三级地址
            thiurl = soup.find('div',class_="image_div").find('img').get('src')
            imgurl=url+thiurl        
            writepage(num, imgurl, imgnamelist[i])
        i+=1
    print ('全部下载已完成...')


def writepage( num, imgurl, imgname):
    """
    下载数据
    """
    path = 'F:/BeautyPic/%s/%s/%s'%(menulist[num],imgname,imgurl[-10:])
    #三级地址，即图片地址载入
    #此处要用res.content，二进制写入
    res = requests.get(imgurl, headers=headers)
    image=res.content
    print('正在下载...')
    print(path)
    with open(path,'wb') as f: 
        f.write(image)
    print('当前项下载已完成...')
        
        
if __name__ == '__main__':
    menu()    
 ```
 ***
 ### to be continued...
